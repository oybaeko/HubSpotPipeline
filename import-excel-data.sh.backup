#!/bin/bash

# Enhanced HubSpot Excel Import Script with CRM File Validation
# 
# Features:
# - Validates Excel data against original CRM export files
# - Extracts download timestamps from file metadata
# - Adds download_timestamp to snapshot data
# - Performs preflight checks before import
#
# Usage: 
#   ./import-excel-data.sh [ENVIRONMENT] [EXCEL_FILE] [OPTIONS]

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Configuration
PROJECT_ID="hubspot-452402"
DEFAULT_EXCEL_FILE="pipeline-import.xlsx"
DEFAULT_DOWNLOAD_DIR="$HOME/Downloads"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
IMPORT_SCRIPT="$SCRIPT_DIR/import_excel.py"

function get_dataset_for_env() {
    local env=$1
    case $env in
        dev) echo "Hubspot_dev_ob" ;;
        staging) echo "Hubspot_staging" ;;
        prod) echo "Hubspot_prod" ;;
        *) echo "Hubspot_dev_ob" ;;
    esac
}

function print_header() {
    echo -e "${BOLD}${BLUE}================================================================${NC}"
    echo -e "${BOLD}${BLUE}     Enhanced HubSpot Excel Import with CRM File Validation${NC}"
    echo -e "${BOLD}${BLUE}================================================================${NC}"
    echo -e "${CYAN}üìä Import historical HubSpot data from Excel to BigQuery${NC}"
    echo -e "${CYAN}‚úÖ Validate against original CRM export files${NC}"
    echo -e "${CYAN}‚è∞ Extract download timestamps from file metadata${NC}"
    echo -e "${CYAN}üéØ Target: $PROJECT_ID datasets${NC}"
    echo -e "${BLUE}================================================================${NC}"
    echo ""
}

function find_crm_export_files() {
    local download_dir=$1
    local snapshot_date=$2
    
    # Look for files matching the pattern - try exact date first, then nearby dates
    local company_pattern="hubspot-crm-exports-weekly-status-company-${snapshot_date}*"
    local deals_pattern="hubspot-crm-exports-weekly-status-deals-${snapshot_date}*"
    
    local company_files=($(find "$download_dir" -name "$company_pattern" 2>/dev/null))
    local deals_files=($(find "$download_dir" -name "$deals_pattern" 2>/dev/null))
    
    # If exact date not found, try nearby dates (¬±3 days)
    if [ ${#company_files[@]} -eq 0 ] || [ ${#deals_files[@]} -eq 0 ]; then
        # Convert date to search nearby dates
        if command -v date >/dev/null 2>&1; then
            local base_date=$(date -j -f "%Y-%m-%d" "$snapshot_date" "+%s" 2>/dev/null || date -d "$snapshot_date" "+%s" 2>/dev/null)
            
            if [ -n "$base_date" ]; then
                # Search ¬±3 days around the snapshot date
                for days_offset in -3 -2 -1 1 2 3; do
                    local search_timestamp=$((base_date + days_offset * 86400))
                    local search_date
                    
                    # Try macOS date format first, then Linux
                    if search_date=$(date -r "$search_timestamp" "+%Y-%m-%d" 2>/dev/null); then
                        :  # macOS format worked
                    elif search_date=$(date -d "@$search_timestamp" "+%Y-%m-%d" 2>/dev/null); then
                        :  # Linux format worked
                    else
                        continue  # Skip this offset if date parsing fails
                    fi
                    
                    # Search for files with this date
                    if [ ${#company_files[@]} -eq 0 ]; then
                        local alt_company_pattern="hubspot-crm-exports-weekly-status-company-${search_date}*"
                        local alt_company_files=($(find "$download_dir" -name "$alt_company_pattern" 2>/dev/null))
                        if [ ${#alt_company_files[@]} -gt 0 ]; then
                            company_files=("${alt_company_files[@]}")
                        fi
                    fi
                    
                    if [ ${#deals_files[@]} -eq 0 ]; then
                        local alt_deals_pattern="hubspot-crm-exports-weekly-status-deals-${search_date}*"
                        local alt_deals_files=($(find "$download_dir" -name "$alt_deals_pattern" 2>/dev/null))
                        if [ ${#alt_deals_files[@]} -gt 0 ]; then
                            deals_files=("${alt_deals_files[@]}")
                        fi
                    fi
                    
                    # Break if we found both files
                    if [ ${#company_files[@]} -gt 0 ] && [ ${#deals_files[@]} -gt 0 ]; then
                        break
                    fi
                done
            fi
        fi
    fi
    
    echo "${company_files[@]} ${deals_files[@]}"
}

function get_file_download_timestamp() {
    local file_path=$1
    
    if [ ! -f "$file_path" ]; then
        echo ""
        return
    fi
    
    # Get file modification time in ISO format with timezone
    if command -v stat >/dev/null 2>&1; then
        # Try different stat formats (macOS vs Linux)
        if stat -f "%Sm" -t "%Y-%m-%dT%H:%M:%S%z" "$file_path" 2>/dev/null; then
            return
        elif stat -c "%y" "$file_path" 2>/dev/null | sed 's/ /T/' | sed 's/\([0-9][0-9]\)$/:\1/'; then
            return
        fi
    fi
    
    # Fallback: use ls and try to parse
    local ls_date=$(ls -l "$file_path" 2>/dev/null | awk '{print $6, $7, $8}')
    if [ -n "$ls_date" ]; then
        # This is a rough conversion - may not be perfect
        date -j -f "%b %d %H:%M" "$ls_date" "+%Y-%m-%dT%H:%M:%S%z" 2>/dev/null || echo ""
    else
        echo ""
    fi
}

function validate_crm_files() {
    local excel_file=$1
    local download_dir=$2
    local preflight_only=$3
    
    echo -e "${BLUE}üîç Validating CRM export files...${NC}"
    echo -e "${CYAN}Excel file: $excel_file${NC}"
    echo -e "${CYAN}Download directory: $download_dir${NC}"
    echo ""
    
    # Get snapshot dates from Excel validation output
    echo -e "${BLUE}üìã Running Excel validation to extract snapshot dates...${NC}"
    local validation_output=$($PYTHON_CMD "$IMPORT_SCRIPT" "$excel_file" --mode validate 2>&1)
    
    # Debug: show validation output if needed
    if [ "$DEBUG_VALIDATION" = "true" ]; then
        echo -e "${YELLOW}Debug - Full validation output:${NC}"
        echo "$validation_output"
        echo ""
    fi
    
    # Extract snapshot dates from validation output - look for the configured snapshots section
    local snapshot_dates=($(echo "$validation_output" | grep "üì∏ Configured snapshots" -A 20 | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}" | sort -u))
    
    # Alternative: extract from auto-detected sheets
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        snapshot_dates=($(echo "$validation_output" | grep "Auto-detected HubSpot sheet:" | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}" | sort -u))
    fi
    
    # Alternative: extract all dates in the output
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        snapshot_dates=($(echo "$validation_output" | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}" | sort -u))
    fi
    
    # If still no dates, try hardcoded fallback from schema
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Could not extract snapshot dates from validation output${NC}"
        echo -e "${BLUE}üí° Using configured snapshot dates from schema...${NC}"
        
        # Hardcoded dates from your schema configuration
        snapshot_dates=("2025-03-21" "2025-03-23" "2025-04-04" "2025-04-06" "2025-04-14" "2025-04-27" "2025-05-11" "2025-05-18" "2025-05-25" "2025-06-01")
        
        echo -e "${CYAN}Using configured dates: ${snapshot_dates[*]}${NC}"
    fi
    
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        echo -e "${RED}‚ùå Could not determine snapshot dates${NC}"
        echo -e "${YELLOW}üí° Debug the validation output:${NC}"
        echo -e "${YELLOW}    DEBUG_VALIDATION=true $0 $*${NC}"
        return 1
    fi
    
    echo -e "${GREEN}üì∏ Found ${#snapshot_dates[@]} snapshot dates in Excel:${NC}"
    for date in "${snapshot_dates[@]}"; do
        echo -e "${GREEN}  ‚Ä¢ $date${NC}"
    done
    echo ""
    
    local validation_results=()
    local total_found=0
    local total_missing=0
    local validation_passed=true
    
    echo -e "${BLUE}üîç Searching for corresponding CRM export files...${NC}"
    echo ""
    
    for snapshot_date in "${snapshot_dates[@]}"; do
        echo -e "${CYAN}üìÖ Checking snapshot: $snapshot_date${NC}"
        
        # Find CRM files for this date
        local crm_files=($(find_crm_export_files "$download_dir" "$snapshot_date"))
        
        local company_file=""
        local deals_file=""
        local company_timestamp=""
        local deals_timestamp=""
        
        # Categorize found files
        for file in "${crm_files[@]}"; do
            if [[ "$file" == *"company"* ]]; then
                company_file="$file"
                company_timestamp=$(get_file_download_timestamp "$file")
            elif [[ "$file" == *"deals"* ]]; then
                deals_file="$file"
                deals_timestamp=$(get_file_download_timestamp "$file")
            fi
        done
        
        # Report findings
        if [ -n "$company_file" ]; then
            echo -e "${GREEN}  ‚úÖ Company file: $(basename "$company_file")${NC}"
            echo -e "${BLUE}     üìÖ Downloaded: ${company_timestamp:-"unknown"}${NC}"
            # Check if this is a different date than snapshot
            local file_date=$(basename "$company_file" | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}")
            if [ "$file_date" != "$snapshot_date" ]; then
                echo -e "${YELLOW}     ‚ö†Ô∏è  File date ($file_date) differs from snapshot date ($snapshot_date)${NC}"
            fi
            ((total_found++))
        else
            echo -e "${RED}  ‚ùå Company file: NOT FOUND${NC}"
            echo -e "${YELLOW}     üîç Looking for: hubspot-crm-exports-weekly-status-company-${snapshot_date}* (¬±3 days)${NC}"
            ((total_missing++))
            validation_passed=false
        fi
        
        if [ -n "$deals_file" ]; then
            echo -e "${GREEN}  ‚úÖ Deals file: $(basename "$deals_file")${NC}"
            echo -e "${BLUE}     üìÖ Downloaded: ${deals_timestamp:-"unknown"}${NC}"
            # Check if this is a different date than snapshot
            local file_date=$(basename "$deals_file" | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}")
            if [ "$file_date" != "$snapshot_date" ]; then
                echo -e "${YELLOW}     ‚ö†Ô∏è  File date ($file_date) differs from snapshot date ($snapshot_date)${NC}"
            fi
            ((total_found++))
        else
            echo -e "${RED}  ‚ùå Deals file: NOT FOUND${NC}"
            echo -e "${YELLOW}     üîç Looking for: hubspot-crm-exports-weekly-status-deals-${snapshot_date}* (¬±3 days)${NC}"
            ((total_missing++))
            validation_passed=false
        fi
        
        # Store validation result
        validation_results+=("$snapshot_date|$company_file|$deals_file|$company_timestamp|$deals_timestamp")
        echo ""
    done
    
    # Summary
    echo -e "${BOLD}${BLUE}üìä CRM FILE VALIDATION SUMMARY${NC}"
    echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
    echo -e "${GREEN}‚úÖ Files found: $total_found${NC}"
    echo -e "${RED}‚ùå Files missing: $total_missing${NC}"
    echo -e "${BLUE}üì∏ Snapshots checked: ${#snapshot_dates[@]}${NC}"
    
    if [ "$validation_passed" = true ]; then
        echo -e "${GREEN}üéâ ALL CRM FILES FOUND - VALIDATION PASSED${NC}"
    else
        echo -e "${RED}‚ùå MISSING CRM FILES - VALIDATION FAILED${NC}"
        echo -e "${YELLOW}üí° Make sure all CRM export files are in: $download_dir${NC}"
        echo -e "${YELLOW}üí° Files should match pattern: hubspot-crm-exports-weekly-status-{company|deals}-YYYY-MM-DD${NC}"
    fi
    
    echo ""
    
    # If this is preflight only, stop here
    if [ "$preflight_only" = "true" ]; then
        return $([ "$validation_passed" = true ] && echo 0 || echo 1)
    fi
    
    # Store validation results for use in import
    export CRM_VALIDATION_RESULTS="${validation_results[@]}"
    return $([ "$validation_passed" = true ] && echo 0 || echo 1)
}

function show_preflight_check() {
    local env=$1
    local excel_file=$2
    local download_dir=$3
    local skip_crm_validation=$4
    
    echo -e "\n${PURPLE}üöÄ PREFLIGHT CHECK${NC}"
    echo -e "${PURPLE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
    echo -e "${CYAN}Environment: $env${NC}"
    echo -e "${CYAN}Dataset: $(get_dataset_for_env "$env")${NC}"
    echo -e "${CYAN}Excel file: $excel_file${NC}"
    if [ "$skip_crm_validation" != "true" ]; then
        echo -e "${CYAN}Download directory: $download_dir${NC}"
    fi
    echo ""
    
    # Run Excel validation
    echo -e "${BLUE}1Ô∏è‚É£ Validating Excel file structure...${NC}"
    if $PYTHON_CMD "$IMPORT_SCRIPT" "$excel_file" --mode validate --log-level WARN >/dev/null 2>&1; then
        echo -e "${GREEN}   ‚úÖ Excel structure is valid${NC}"
    else
        echo -e "${RED}   ‚ùå Excel validation failed${NC}"
        return 1
    fi
    
    # Run CRM file validation (unless skipped)
    if [ "$skip_crm_validation" != "true" ]; then
        echo -e "${BLUE}2Ô∏è‚É£ Validating CRM export files...${NC}"
        if validate_crm_files "$excel_file" "$download_dir" "true"; then
            echo -e "${GREEN}   ‚úÖ All CRM files found and validated${NC}"
        else
            echo -e "${YELLOW}   ‚ö†Ô∏è  CRM file validation failed${NC}"
            echo -e "${YELLOW}   üí° Use --skip-crm-validation to import without CRM validation${NC}"
            return 1
        fi
    else
        echo -e "${BLUE}2Ô∏è‚É£ Skipping CRM file validation...${NC}"
        echo -e "${YELLOW}   ‚ö†Ô∏è  CRM validation skipped - importing Excel data only${NC}"
    fi
    
    # Check BigQuery access
    echo -e "${BLUE}3Ô∏è‚É£ Checking BigQuery access...${NC}"
    local dataset=$(get_dataset_for_env "$env")
    if bq ls "$PROJECT_ID:$dataset" >/dev/null 2>&1; then
        echo -e "${GREEN}   ‚úÖ BigQuery dataset accessible${NC}"
    else
        echo -e "${RED}   ‚ùå Cannot access BigQuery dataset: $dataset${NC}"
        return 1
    fi
    
    echo -e "\n${GREEN}üéâ ALL PREFLIGHT CHECKS PASSED${NC}"
    echo -e "${GREEN}‚úÖ Ready for import${NC}"
    return 0
}

function check_prerequisites() {
    echo -e "${BLUE}üîç Checking prerequisites...${NC}"
    
    # Check if Python import script exists
    if [ ! -f "$IMPORT_SCRIPT" ]; then
        echo -e "${RED}‚ùå Python import script not found: $IMPORT_SCRIPT${NC}"
        echo -e "${YELLOW}üí° Make sure you're running this from the project root directory${NC}"
        return 1
    fi
    
    # Check if Python is available
    if ! command -v python3 &> /dev/null && ! command -v python &> /dev/null; then
        echo -e "${RED}‚ùå Python not found${NC}"
        echo -e "${YELLOW}üí° Install Python 3.7+ to continue${NC}"
        return 1
    fi
    
    # Determine Python command
    if command -v python3 &> /dev/null; then
        PYTHON_CMD="python3"
    else
        PYTHON_CMD="python"
    fi
    
    # Check if gcloud is available
    if ! command -v gcloud &> /dev/null; then
        echo -e "${RED}‚ùå gcloud CLI not found${NC}"
        echo -e "${YELLOW}üí° Install: https://cloud.google.com/sdk/docs/install${NC}"
        return 1
    fi
    
    # Check authentication
    if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" &> /dev/null; then
        echo -e "${RED}‚ùå Not authenticated with gcloud${NC}"
        echo -e "${YELLOW}üí° Run: gcloud auth login${NC}"
        return 1
    fi
    
    # Set project
    current_project=$(gcloud config get-value project 2>/dev/null)
    if [ "$current_project" != "$PROJECT_ID" ]; then
        echo -e "${YELLOW}üîß Setting project to $PROJECT_ID...${NC}"
        gcloud config set project $PROJECT_ID
    fi
    
    echo -e "${GREEN}‚úÖ Prerequisites check passed${NC}"
    return 0
}

function check_excel_file() {
    local excel_file=$1
    
    if [ ! -f "$excel_file" ]; then
        echo -e "${RED}‚ùå Excel file not found: $excel_file${NC}"
        
        # Look for common variations
        echo -e "${YELLOW}üîç Looking for Excel files in current directory...${NC}"
        local excel_files=$(find . -maxdepth 1 -name "*.xlsx" -o -name "*.xls" 2>/dev/null)
        
        if [ -n "$excel_files" ]; then
            echo -e "${CYAN}Found Excel files:${NC}"
            echo "$excel_files" | while read file; do
                echo -e "${CYAN}  ‚Ä¢ $file${NC}"
            done
            echo -e "${YELLOW}üí° Specify the correct file: $0 $ENVIRONMENT filename.xlsx${NC}"
        else
            echo -e "${YELLOW}üí° No Excel files found in current directory${NC}"
            echo -e "${YELLOW}üí° Make sure the Excel file exists and try again${NC}"
        fi
        return 1
    fi
    
    # Check file extension
    if [[ ! "$excel_file" =~ \.(xlsx|xls)$ ]]; then
        echo -e "${RED}‚ùå File must be Excel format (.xlsx or .xls): $excel_file${NC}"
        return 1
    fi
    
    echo -e "${GREEN}‚úÖ Excel file found: $excel_file${NC}"
    return 0
}

function check_download_directory() {
    local download_dir=$1
    
    if [ ! -d "$download_dir" ]; then
        echo -e "${RED}‚ùå Download directory not found: $download_dir${NC}"
        echo -e "${YELLOW}üí° Specify correct directory with --download-dir option${NC}"
        return 1
    fi
    
    # Count potential CRM files
    local crm_files=$(find "$download_dir" -name "hubspot-crm-exports-weekly-status-*" 2>/dev/null | wc -l)
    
    echo -e "${GREEN}‚úÖ Download directory found: $download_dir${NC}"
    echo -e "${CYAN}üìÅ Found $crm_files CRM export files${NC}"
    
    if [ "$crm_files" -eq 0 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  No CRM export files found in download directory${NC}"
        echo -e "${YELLOW}üí° Make sure CRM files are in the correct directory${NC}"
    fi
    
    return 0
}

function setup_environment() {
    local env=$1
    local dataset=$(get_dataset_for_env "$env")
    
    echo -e "${BLUE}üîß Setting up environment for $env...${NC}"
    
    # Check if .env file exists
    local env_file="$SCRIPT_DIR/.env"
    if [ ! -f "$env_file" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  .env file not found, creating one...${NC}"
        
        # Create basic .env file
        cat > "$env_file" << EOF
# BigQuery Configuration for Excel Import
BIGQUERY_PROJECT_ID=$PROJECT_ID
BIGQUERY_DATASET_ID=$dataset

# Google Cloud Authentication
# GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
EOF
        echo -e "${GREEN}‚úÖ Created .env file: $env_file${NC}"
        echo -e "${YELLOW}üí° Update GOOGLE_APPLICATION_CREDENTIALS if using service account${NC}"
    else
        echo -e "${GREEN}‚úÖ Found .env file${NC}"
    fi
    
    # Update dataset in .env file for this run
    if command -v sed &> /dev/null; then
        sed -i.bak "s/^BIGQUERY_DATASET_ID=.*/BIGQUERY_DATASET_ID=$dataset/" "$env_file"
        echo -e "${GREEN}‚úÖ Updated dataset to: $dataset${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Please manually update BIGQUERY_DATASET_ID=$dataset in .env${NC}"
    fi
    
    echo -e "${CYAN}üìä Target dataset: $dataset${NC}"
}

function confirm_import() {
    local env=$1
    local excel_file=$2
    local dry_run=$3
    
    echo -e "\n${YELLOW}‚ö†Ô∏è  IMPORT CONFIRMATION${NC}"
    
    if [ "$dry_run" = "true" ]; then
        echo -e "${BLUE}This is a DRY RUN - no data will be written to BigQuery${NC}"
        read -p "$(echo -e ${GREEN}Press Enter to continue with dry run...${NC})"
        return 0
    fi
    
    echo -e "${YELLOW}This will import data to $env environment${NC}"
    echo -e "${YELLOW}Excel file: $excel_file${NC}"
    echo -e "${YELLOW}Target dataset: $(get_dataset_for_env "$env")${NC}"
    echo -e "${YELLOW}CRM file validation: completed${NC}"
    
    if [ "$env" = "prod" ]; then
        echo -e "\n${RED}üö® THIS IS PRODUCTION! üö®${NC}"
        echo -e "${RED}Data will be written to production BigQuery tables${NC}"
        read -p "$(echo -e ${RED}Type 'IMPORT TO PRODUCTION' to continue: ${NC})" confirm
        if [ "$confirm" != "IMPORT TO PRODUCTION" ]; then
            echo -e "${YELLOW}‚ùå Import cancelled${NC}"
            exit 0
        fi
    else
        read -p "$(echo -e ${YELLOW}Type 'yes' to continue: ${NC})" confirm
        if [ "$confirm" != "yes" ]; then
            echo -e "${YELLOW}‚ùå Import cancelled${NC}"
            exit 0
        fi
    fi
}

function run_import_with_crm_metadata() {
    local env=$1
    local excel_file=$2
    local mode=$3
    local dry_run_flag=$4
    local extra_args="$5"
    local download_dir="$6"
    
    echo -e "\n${YELLOW}üöÄ Starting Excel import with CRM metadata...${NC}"
    
    # Extract CRM metadata and create mapping file
    local crm_metadata_file="/tmp/crm_metadata_$.json"
    
    echo -e "${BLUE}üìã Extracting CRM file metadata...${NC}"
    if ! create_crm_metadata_file "$excel_file" "$download_dir" "$crm_metadata_file"; then
        echo -e "${RED}‚ùå Failed to extract CRM metadata${NC}"
        return 1
    fi
    
    echo -e "${CYAN}üìÑ CRM metadata saved to: $crm_metadata_file${NC}"
    
    # Add CRM metadata file to extra args
    extra_args="$extra_args --crm-metadata \"$crm_metadata_file\""
    
    # Build the full command
    local cmd="$PYTHON_CMD \"$IMPORT_SCRIPT\" \"$excel_file\" --mode $mode $dry_run_flag $extra_args"
    
    echo -e "${CYAN}Command: $cmd${NC}"
    echo ""
    
    # Execute the import
    if eval $cmd; then
        echo -e "\n${GREEN}üéâ EXCEL IMPORT WITH CRM METADATA COMPLETED SUCCESSFULLY${NC}"
        
        if [ "$dry_run_flag" != "--dry-run" ]; then
            echo -e "${GREEN}‚úÖ Data imported to $(get_dataset_for_env "$env") with CRM timestamps${NC}"
            echo -e "${GREEN}‚úÖ Snapshot IDs based on actual CRM file download times${NC}"
            echo -e "${CYAN}üí° Query your data using the CRM-based snapshot_id timestamps${NC}"
        else
            echo -e "${BLUE}üõë This was a dry run - no data was actually imported${NC}"
            echo -e "${CYAN}üí° Remove --dry-run to perform the actual import${NC}"
        fi
        
        # Clean up metadata file
        rm -f "$crm_metadata_file"
        
    else
        echo -e "\n${RED}‚ùå EXCEL IMPORT WITH CRM METADATA FAILED${NC}"
        echo -e "${YELLOW}üí° Check the error messages above for details${NC}"
        
        # Clean up metadata file
        rm -f "$crm_metadata_file"
        return 1
    fi
}

function create_crm_metadata_file() {
    local excel_file=$1
    local download_dir=$2
    local output_file=$3
    
    # Get snapshot dates from Excel validation
    local validation_output=$($PYTHON_CMD "$IMPORT_SCRIPT" "$excel_file" --mode validate 2>&1)
    
    # Extract snapshot dates
    local snapshot_dates=($(echo "$validation_output" | grep "üì∏ Configured snapshots" -A 20 | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}" | sort -u))
    
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        snapshot_dates=($(echo "$validation_output" | grep -oE "20[0-9]{2}-[0-9]{2}-[0-9]{2}" | sort -u))
    fi
    
    if [ ${#snapshot_dates[@]} -eq 0 ]; then
        echo -e "${RED}‚ùå Could not extract snapshot dates from Excel${NC}"
        return 1
    fi
    
    # Create JSON metadata file
    echo "{" > "$output_file"
    echo "  \"crm_file_metadata\": {" >> "$output_file"
    
    local first_entry=true
    local successful_mappings=0
    
    for snapshot_date in "${snapshot_dates[@]}"; do
        echo -e "${CYAN}  üîç Processing snapshot: $snapshot_date${NC}"
        
        # Find CRM files for this date (with ¬±3 days search)
        local crm_files=($(find_crm_export_files "$download_dir" "$snapshot_date"))
        
        local company_file=""
        local deals_file=""
        local company_timestamp=""
        local deals_timestamp=""
        
        # Categorize found files
        for file in "${crm_files[@]}"; do
            if [[ "$file" == *"company"* ]]; then
                company_file="$file"
                company_timestamp=$(get_file_download_timestamp "$file")
            elif [[ "$file" == *"deals"* ]]; then
                deals_file="$file"
                deals_timestamp=$(get_file_download_timestamp "$file")
            fi
        done
        
        # Only include snapshots where we have both files
        if [ -n "$company_file" ] && [ -n "$deals_file" ] && [ -n "$company_timestamp" ] && [ -n "$deals_timestamp" ]; then
            
            # Use the earlier of the two timestamps as the snapshot_id
            local snapshot_timestamp="$company_timestamp"
            if [[ "$deals_timestamp" < "$company_timestamp" ]]; then
                snapshot_timestamp="$deals_timestamp"
            fi
            
            # Add comma if not first entry
            if [ "$first_entry" = false ]; then
                echo "," >> "$output_file"
            fi
            first_entry=false
            
            # Add metadata entry
            cat >> "$output_file" << EOF
    "$snapshot_date": {
      "snapshot_id": "$snapshot_timestamp",
      "company_file": "$company_file",
      "deals_file": "$deals_file",
      "company_timestamp": "$company_timestamp",
      "deals_timestamp": "$deals_timestamp"
    }EOF
            
            echo -e "${GREEN}    ‚úÖ Mapped to CRM timestamp: $snapshot_timestamp${NC}"
            ((successful_mappings++))
        else
            echo -e "${YELLOW}    ‚ö†Ô∏è  Skipping - missing CRM files or timestamps${NC}"
        fi
    done
    
    echo "" >> "$output_file"
    echo "  }" >> "$output_file"
    echo "}" >> "$output_file"
    
    echo -e "${GREEN}üìä Successfully mapped $successful_mappings snapshots to CRM timestamps${NC}"
    
    if [ "$successful_mappings" -eq 0 ]; then
        echo -e "${RED}‚ùå No snapshots could be mapped to CRM files${NC}"
        return 1
    fi
    
    return 0
}

function show_help() {
    echo "Enhanced HubSpot Excel Import Script with CRM File Validation"
    echo ""
    echo "Features:"
    echo "  ‚úÖ Validates Excel data against original CRM export files"
    echo "  ‚è∞ Uses actual CRM file download timestamps as snapshot_id"
    echo "  üîç Performs comprehensive preflight checks"
    echo "  üìä Imports Excel data with CRM-based timestamps"
    echo ""
    echo "Usage: $0 [ENVIRONMENT] [EXCEL_FILE] [OPTIONS]"
    echo ""
    echo "Arguments:"
    echo "  ENVIRONMENT    Target environment (dev|staging|prod)"
    echo "  EXCEL_FILE     Excel file to import (default: $DEFAULT_EXCEL_FILE)"
    echo ""
    echo "Options:"
    echo "  --mode MODE           Import mode (snapshots|auto|validate) [default: snapshots]"
    echo "  --dry-run            Preview import without writing to BigQuery"
    echo "  --download-dir DIR   Directory containing CRM export files [default: ~/Downloads]"
    echo "  --preflight-only     Run preflight checks only, don't import"
    echo "  --skip-crm-validation Skip CRM file validation (import Excel only)"
    echo "  --snapshot-id ID     Custom snapshot ID for auto mode"
    echo "  --log-level LEVEL    Set logging level (DEBUG|INFO|WARN|ERROR)"
    echo "  --force              Skip confirmation prompts"
    echo "  --help, -h           Show this help message"
    echo ""
    echo "Import Modes:"
    echo "  snapshots   Import configured snapshots with CRM validation (default)"
    echo "  auto        Auto-detect sheets and import as single snapshot"
    echo "  validate    Validate Excel and CRM file structure"
    echo ""
    echo "Examples:"
    echo "  $0 dev --preflight-only                                    # Just run checks"
    echo "  $0 dev                                                     # Import with validation"
    echo "  $0 staging my-data.xlsx --dry-run --download-dir ./files  # Custom directory"
    echo "  $0 prod pipeline-import.xlsx --mode snapshots             # Full import to prod"
    echo ""
    echo "CRM File Pattern:"
    echo "  hubspot-crm-exports-weekly-status-company-YYYY-MM-DD"
    echo "  hubspot-crm-exports-weekly-status-deals-YYYY-MM-DD"
}

# Run main function with all arguments
main "$@"